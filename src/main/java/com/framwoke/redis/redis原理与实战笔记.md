# SimpleKV

整体架构和核心模块 SimpleKV 数据模型与操作接口 键值数据库： 1。不包含聚合运算 2。基本数据模型 key-value

value支持的数据结构体现在：性能，空间利用差异 基本操作：put/set ，get ， delete ， scan ，exists

不同操作对redis访问速率的影响

内存：读写快，断电数据丢失 硬盘：效率受外部键盘读写影响

基本组件： 访问框架，索引模块，存储模块 访问模式：函数库调用（动态链接库）/ 网络框架

通讯：网络链接处理，网络协议解析，数据存储

索引模块（哈希表，B+树，字典树）选型体现：性能，空间差异，并发控制

内存分配器格外重要

持久化方式：文件

作业：实现一个SimpleKV，键值对 问题：SimpleKV 与redis的区别

# 认识redis

为什么快？ 内存读写 + 高效的数据结构

底层数据结构（六种）：简单动态字符串，列表，哈希表，跳表，压缩列表，整型数组

键值结构组织： 哈希表 ， 哈希桶（一个数组，保存的是entry），entry（key和value的指针） 哈希冲突：链式哈希，同一个哈希桶中的entry元素，通过next指针形成链表，也叫哈希冲突链。
为解决哈希链表过长而导致查询缓慢问题，引入rehash机制

rehash原理：

rehash时机：渐进性hash与定时任务

慢操作有那些？与数据结构有关系

压缩列表：类似数组，但在表头有三个字段表示长度（zlbytes），尾部偏移量（zltail），entry个数（zllen） 跳表：多级索引，金字塔结构

四字口诀：单元素操作是基础，范围查找非常耗时，统计高效，

redis 为什么快

底层数据结构（六种）：

哈希冲突 rehash 装载因子

集合数据如何操作

相关命令： 单元素操作是基础:
范围操作非常耗时；SCAN 统计操作通常高效； 例外情况只有几个

为什么说redis是单线程的： 单线程IO+多写单线程 数据结构+多路复用机制

网络IO处理:accept ，recv select + epoll

非阻塞模式：主动socket ， 被动/监听socket

IO多路复用机制：一个线程处理多个IO流，允许多个

持久化：AOF日志+RDB快照

写后日志（主线程）：先执行命令后存储文件，记录每一条命令。 1。避免错误命令的记录/不产生阻塞 2。风险：写命令/写磁盘 配置项： 同步写回：高可靠性，影响性能，数据会丢失 每秒写回：避免影响性能，数据会丢失，折中 操作系统控制写回：

AOF重写机制（子线程）：

内存快照：内存中的数据在某一时刻的状态 1。 对那些数据做快照（取景问题）：全量快照 save（阻塞） 和bgsave（非阻塞） 2。 快照执行期间是否可被修改：写操作时，主线程生成副本，bgsave会直接读取副本生成快照 3。
什么时候生成快照：频率-磁盘压力/fork操作阻塞主线程-> 增量快照（引用额外空间）

4.0版本以上提出混合使用概念：不同时刻修改记录AOF，生成快照后清空AOF

宕机-如何恢复

主从库同步，多写分离，主写从读 命令：replicaof 三个阶段：主从建立链接， 生成RDB文件，传输RDB文件 主-从-从及联模式分担全量同步压力，和fork开销

replication buffer and rep_backlog_buffer

rep_backlog_buffer 环形缓存区：从库读写慢时会导致数据不一致

三种模式：

主库发生故障，会影响同步与写操作，故需要故障转移即哨兵机制

哨兵机制基本流程：监控，选主，通知

监控： 主观下线 和 客观下线 误判 引入多实例哨兵集群，减少误判， 少数服从多数 (n/2 +1)

选主： 筛选条件：在线状态+网络状态 打分（三轮）：优先级（高） + 复制进度（快） + 从库ID（小）

哨兵集群

多实例间，通过pub/sub 发布订阅机制与主库产生联系，从而获取各个实例的ip和端口，从而相互之间就可建立链接。 通过主库info命令，获取从库信息，

quorum值

哨兵实例宕机后的Leader哨兵选举

只有两个实例时，需要拿到2票才能进行主从切换，如果其中一个宕机，则会导致无法进行故障转移。故哨兵集群至少需要三个实例。

保证所有的哨兵实例配置一直，down-after-milliseconds主管下线的判断值，否者会导致无法达成一致

# 切片（分片）集群

latest_fork_usec 指标： 最近一次fork耗时

纵向扩展：持久化时，增量数据导致阻塞，且受硬件和成本限制 横向扩展：

切片集群和redis cluster的区别

redis cluster ： 采用hash slot(哈希槽)，共有16384个 cluster create : 自动均分hash slot命令 cluster meet: 手动建立实例链接，生成集群 cluster addslots:
手动分配hash槽，需要注意的是，需要全部分配16384个，集群才可用

客户端如何找到数据在哪个实例上

重定向机制

主线程，子进程，后台线程

问题： 这些数据结构都是值的底层实现，键和值本身之间用什么结构组织？ 为什么集合类型有那么多的底层结构，它们都是怎么组织数据的，都很快吗？ 什么是简单动态字符串，和常用的字符串是一回事吗？

# 答疑

    - 两大维度，三大主线
        - 应用纬度：数据结构，缓存策略，集群应用
        - 系统纬度：底层数据结构，内存分配器 ，持久化，集群
    - 整数数组和压缩列表
        - 整数数组内存分配紧凑，避免开销
    - 基本IO模型潜在性能瓶颈
    - AOF 重写过程风险
        - 复制过程，阻塞主线程
        - 
    - 内存资源和CPU资源
        - swap机制
        - 主线程/子线程/后台线程 竞争CPU
    - 主从库不使用AOF，而使用RDB
    - 主从切换能否进行正常操作
    - 无感知中断
        - 哨兵
    - 哨兵-主/客观下线判断
    - 为什么不将实例和键值对关联存储成表？

* rehash 时机和执行机制

# 学习redis三本参考书+命令网站+源码阅读

# 如何学习redis

    -掌握数据结构和缓存的基本操作方法
        - 底层数据结构
        - 五种基础数据类型+三种拓展数据类型（HypeLoglog/Geo/BitMap）
        - 典型问题的解决方案：穿透/雪崩
        - 持久化/切片集群（高可靠，高性能，易扩展）
    -主从复制/哨兵/切片集群/持久化（AOF/RDB）
        - 高可靠性：持久化 -> 故障恢复（主从恢复）-> 自动主从切换（哨兵）
        - 高性能：单机 -> Cluster集群（水平扩展能力-扩容/容灾能力）
    redis性能问题：
        - 使用层面
        - 运维层面
    -分布式系统原理
        - 分布式CAP
        - 分布式事务

    1。保持好奇心-思考和挖掘能力
    2。不要自我设限
    3。源码实战（二八定律）
    4。文章输出（对知识的梳理）
    5。系统化学习，细化任务（番茄学习法）
    6。时间成本和精力投入

# redis 客户端

    - RESP2 协议
        - 交互内容：命令/键/值/键值ok回复/整数回复/错误信息
        - 五种编码格式类型
            - 简单字符串类型
            - 长字符串类型（二进制安全）
            - 整数类型
            - 错误类型
            - 数组类型

# QA

* Redis 缓存具体是怎么工作的？
* Redis 缓存如果满了，该怎么办？
* 为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？
* Redis 的内存毕竟有限，如果用快速的固态硬盘来保存数据，可以增加缓存的数据量，那么，Redis 缓存可以使用快速固态硬盘吗？

热key 提高访问速度 计算机三层存储架构：CPU，内存，磁盘 CPU末级缓存LLC用于缓存内存中的数据，内存中的高速页缓存（page cache），用来缓存磁盘中的数据。
1。缓存一定是一个快速子系统（redis），用于避免从慢速子系统（数据库）中获取数据 2。缓存系统容量大小要小于后端慢系统，我们不肯呢个把所有的数据保存在缓存中
3。缓存中的数据需要按照一定的规则淘汰数据，写回后端系统中，而新的数据需要从后端系统中读取并写入缓存 缓存命中 缓存缺失 -> 缓存更新 缓存数据一致性 缓存穿透 缓存击穿 缓存雪崩
只读缓存：读取数据时从redis访问，发生变更时操作数据库，并删除缓存。在缓存缺失时，重新从数据库读取并更新缓存（保障了数据的可靠性，不会丢失）
读写缓存：读写都在redis端，然后使用同步直写（保证数据可靠性，访问速度慢）/异步写回（降低访问延迟，数据有丢失风险）两种策略 缓存数据的淘汰机制： 八二原理：20%的数据贡献了80%的访问 长尾效应和重尾效应？

** 建议缓存容量设置为总数据量的15%-30% 兼顾访问性能和内存开销

## 缓存淘汰策略：

1。 是否回进行数据淘汰-noviction（否）和7种（是） 2。 按照过期时间淘汰（4种）和按照数据范围淘汰（三种）

** 不淘汰数据策略 - noevection策略：缓存空间满的时候(达到了maxmemory值)，不对数据进行淘汰，而是停止提供写入服务并返回错误信息
** 根据过期时间淘汰数据策略 - volatile-random : 对设置了过期时间的键值对，随机淘汰 - volatile-ttl： 对设置了过期时间的键值对，按过期时间的先后顺序进行淘汰 - volatile-lru：
对设置了过期时间的键值对，按最近最少使用的策略进行淘汰 - volatile-lfu： 对设置了过期时间的键值对，按使用频率最少的策略进行淘汰 - allkeys-random： 对所有的键值对，随机淘汰 - allkeys-lru：
对所有的键值对，按最近最少使用的策略进行淘汰 - allkeys-lfu： 对所有的键值对，按使用频率最少的策略进行淘汰

### LRU算法

概述： 维护一个双端链表，最近访问的键值对移动到最左边MRU端，最右端则是LRU端，淘汰数据的时候，从最右端开始往前淘汰

LRU算法因为需要额外的内存空间，以及移动淘汰数据时会对redis性能有所损耗，故redis对该算法进行了些简化。 1。
对每一个数据，其RedisObjec中的lru属性记录最近访问的时间戳。执行淘汰策略的时候，随机从内存中抓取N数据，然后把lru最小的淘汰掉。抓取的数据大小N由配置参数【maxmemory-samples】决定。 2。
当需要再次淘汰数据的时候，会再挑选出一批数据B放入上次的候选淘汰数据集合A中，其中挑选的数据B中的lru要小于候选集合A中的值。当候选集合A的个数到达【maxmemory-samples】的值时，就会触发淘汰，将A中最小的lru淘汰出去。

实战建议：

- 存在冷热数据区分的时候，建议使用allkeys-lru
- 冷热数据区分不明显的时候，建议使用allkeys-random
- 如果业务有置顶需求，建议使用volatile-lru策略，同时对于置顶数据不设置过期时间，这样置顶数据不会过期，而其他的数据可以按照lru策略进行淘汰

### LFU算法

    - 概述： 

### 对淘汰数据的处理
    - 干净的数据，可直接删除
    - 脏读数据，写回数据库。解决方案，缓存发生变更时写回到数据库，或者数据库发生变更时更新缓存数据，以解决脏读问题

### 缓存数据一致性问题
    - 缓存有数据，和数据库值是否一致
    - 缓存无数据，数据库中值是否时最新值 解决方案：
        - 保证缓存和数据库的修改删除的原子性，要么都成功，要么都失败。
        - 通过消息队列的方式，实现重试机制。只有全部更新成功新的数值才从消息队列中删除
        - 在删除/变更数据库和缓存的操作过程，发生了其他线程对于数据的读取，此时有两种情况：
            - 先删除缓存，后更新数据库数据。在数据更新数据库未完成前发生读取请求，出现数据不一致问题，可使用【延迟双删】的方式，减小数据不一致发生的概率。
            - 先更新数据库，后删除缓存。此种情况对于业务影响最小，只有更新db后，删除cache前，很小一部分发生脏读。如果一定要保证数据一致性，可在所有操作完成之前，将用户并发请求暂存，待全部完成后，在执行。

### 缓存雪崩，缓存击穿，缓存穿透问题

    - 缓存雪崩
        - 概述：当大量数据同时过期或者redis实例宕机时，就会导致大量的请求堆积到数据库，从而引发应用不可用。
        - 表现：数据库负载突增/redis实例宕机，导致请求延迟甚至是大量请求无响应
        - 解决方案：
            - 1. 杜绝大量的key同时失效，如果因业务需要则可以对失效时间添加一个一定时间内的随机数比如1-3分钟，这样即可让key在相近时间失效，也可防止其同时大批量失效而打到数据库
            - 2. 熔断降级和限流，当redis实例发生宕机或者发生雪崩时，对缓存接口进行熔断降级，返回预定义信息，比如非核心的属性信息。监控数据库可以支撑的数据压力，当达到阈值时，对接口进行限流。主要针对的时核心数据信息
            - 3. 从redis部署上预防，比如主从节点，当主节点发生宕机的时候，重新选举并提升从节点为主节点，以保证缓存服务高可用。例如sentinel模式
    
    - 缓存击穿
        - 概述： 当高并发发生在热点数据失效时，就会击穿缓存系统，而将压力打到数据库中
        - 表现： 数据库负载突增，热点数据失效
        - 解决方案：
            - 1. 对于热点数据延长其失效时间，甚至是不设置过期时间
    
    - 缓存穿透
        - 概述： 发生高并发时，缓存不被命中，同时也不在数据库中。（主要来源于恶意攻击）
        - 表现： 缓存缺失，数据库压力突增
        - 解决方案：
            - 1. 对不被命中或者为null的值设置缺省值
            - 2. 通过布隆过滤器判断数据是否存在，而减轻数据库压力
            - 3. 接口做安全性校验，防范恶意攻击
    
    - 布隆过滤器
        - 概述： 由一个初始值都为0的数组+N个哈希函数组成，可以快速判断是否数据是否存在
        - 原理： 
            - 1. 使用N个哈希函数，分别计算出该数据的哈希值，得到N个哈希值
            - 2. 把这N个哈希值对Bit数组的长度取模，得到每个哈希值在数组中对应的位置
            - 3. 把得到的位置，标记为1，即表示该数值存在。
        - 运用：判断数值是否存在，重复原理上的第一第二个步骤，如果得到的N个位置，在bit数组对应中存在一个不为1的情况，即表示数据不存在，没有被布隆过滤器标记过
        - 实际使用：
            - 1. 数据写入数据库时，使用布隆过滤器做标记
            - 2. 可使用redis来实现布隆过滤器，可提升访问性能

### 缓存污染

    - 概述： 放于缓存的数据，访问次数较少，甚至无访问，就会一直占用缓存空间，当缓存空间满的时候，需要执行淘汰策略，从而因为执行额外的操作，影响性能，这就是所谓的缓存污染。
    - 解决方案： 
        - 1. volatile-ttl: 在明确数据被访问情况下，可使用volatile-ttl来淘汰数据
        - 2. volatile-lru 和 allkeys-lru 策略：通过使用时间戳来定义最近最少使用淘汰策略，数据范围从过期时间到全部key
        - 3. volatile-lfu 和 allkeys-lfu 策略：在lru基础上，添加count访问计数来定义最近访问频率最小淘汰策略。即从访问时效性和访问次数层面做比较

### 缓存并发访问问题

    - 概述：多个实例访问redis缓存时，会导致数据不一致问题，主要由修改缓存导致
    - 解决方案：加锁/原子性操作
        - 加锁：需要考虑分布式锁，且加锁会阻塞其他操作，导致并发性能下降
        - 原子性操作： 
            - 1. 可以把多个操作，合并成一个操作指令执行，也就是单命令指令，比如INCR和DECR命令。适用于数据简单的增减
            - 2. 使用lua脚本，适用于多层逻辑判断，保障其一次性执行。注意需要避免把不需要并发控制的操作写入脚本中

### 分布式锁

    - 概述：解决分布式系统中加锁问题
    - 要求：
        - 1. 加解锁涉及到多个操作（读锁/检查锁/写锁），需要保证这些操作的原子性
        - 2. 需要设置过期时间，以避免死锁
        - 2. 共享存储系统保存了锁变量，需要保证其唯一性和可靠性，进而保证锁的可靠性
    - 实现：
        - 基于单个节点实现分布式锁：setnx|px|ex 命令 或者lua脚本
        - 基于多节点实现分布式锁： redlock算法（半数以上加锁成功才算成功，且某个节点宕机不影响可用性）

### 事务机制

    - 概述：一个事务中的操作要么全部完成，要么全部失败。即需要提供原子性，一致性，隔离性，持久性等保证，就是所谓的ACID
    - 实现： 通过MULTI 和 EXEC命令实现事务开启与提交，以保证多个操作共同执行。在执行EXEC之前，命令只是放在了队列中，且可以通过DISCARD来取消事务，但不存在事务回滚机制
    - 现象：
        - 1. 命令入队就报错，会导致事务执行失败，可以保证原子性/一致性，比如事务执行过程中，若出现命令非法情况时，所有命令都不会执行
        - 2. 命令入队成功，但执行报错，不保证原子性/一致性，如类型不一致或者非法的情况下，只会提示错误的命令，其他命令将被执行
        - 3. 在执行EXEC命令之前，实例宕机：
            - 开启了AOF ,但事务未写入AOF文件，重新回复后由于事务未写入执行，可保证原子性/一致性
            - 开启了AOF，但部分事务已写入AOF文件，重新回复后，可通过redis-check-aof来清除已经执行的事务，从而保证原子性与一致性
            - 未开启AOF，重启后事务执行数据就都没有了，谈不上原子性，但保证了一致性
            - 开启了RDB，因为事务执行过程中，是无法写入RDB的，所以回复之后也谈不上原子性了，但保证了一致性
        -关于隔离性：
            - 并发操作发生在执行EXEC命令之前，需要通过watch命令来保证隔离性，否则无法保证
            - 发生在EXEC命令之后，则可以保证。因为redis是单线程的。
        -关于持久性：
            - 事务的持久性取决于redis的持久化配置
            - 若未开启aof 和 rdb，则肯定无法保证持久性
            - 事务执行之后，在下一个RDB未写入时发生了实例宕机，则无法保证持久性
            - aof取决与no，everysec，allways三个配置项，但都可能出现数据丢失的情况无法保证持久性
            - 总结：故对于redis来说，其持久性属性都是得不到保证的
        -总结：redis可以保证一致性与隔离性，命令语法正确时可保证原子性，但无法保证持久性，且持久性也不是redis应该关注的点。
    - 实际运用：
        -1. 严格按照redis命令规范执行
        -2. 在使用事务的时候，可通过pipeline来一次性提交命令，即可保证事务隔离性，又提高了性能，避免反复操作而提高IO开销
        -3. 虽然使用了pipline保证了事务隔离性，但在需要保证原子性的情况下，watch命令还是需要的，以避免在执行事务前，数据发生了变更。

### 主从同步与故障切换

    - 概述：通过分库分担主库压力，可实现读写分离的同时，进行故障自动转移和回复，提供高可靠性
    - 现象：主从数据不一致，读到过期数据，配置不合理导致服务挂机
        - 主从数据不一致： 因主从复制异步执行缘故导致从库读取的数据和主库最新数据不一致
            - 1. 主从之间网络延迟，所以我们要尽量保证主从之间硬件层面网络的良好状况
            - 2. 从库虽然接收到了同步命令，但当前可能处于执行其他复杂度高的命令操作（如集合）而阻塞，若这段时间内主库数据再次法身变更，从库数据将不一致。此种情况下，可以利用通过info replicationm命令来提供一个外部监测程序监测主库的进度信息[master-repl-info]和从库的进度信息[slave-repl-info]，当两者进度信息差值超过设置阈值时，将断开从库的读取连接，等数据一致后再回复。但要注意为避免导致大部分甚至时全部从库不可用，这个阈值需要配置大一些。
        - 过期数据脏读：由redis过期数据删除策略而引发的脏读现象。过期删除策略：惰性删除（再次调用时因过期而执行删除，否则将滞留）与定期删除（100ms执行一次随机数据抓取，若过期则删除）
            -1. 删除操作在主库执行，从库不会执行。若是惰性删除策略，在3.2版本以前，redis从库会返回过期数据，但3.2版本之后，从库虽不会删除，但返回空
            -2. 定时删除，为避免影响性能，每次执行的删除数据量不会太大，且是随机的。故已过期未被删除的数据会被滞留而产生脏读
            -3. 过期时间命令EXPIRE 和 PEXPIRE 命令，在主从命令同步时，因为同步需要时间，就会导致主从库实际过期时间出现偏差。比如主库设置过期时间60s，但同步全量花费了1分钟，那么在从库接收到命令并执行之后，就导致从库key的过期时间整体跨越了两分钟，而此时主库在一分钟之前数据就已经过期了。故在实际运用当中建议使用expireat 和 pexpireat 命令来设置过期时间节点。这样可避免增量的发生。但需注意主从服务器时间一致。
        - 

### 关于设置过期时间命令

    - EXPIRE : 过期时间跨度，单位秒
    - PEXPIRE: 过期时间跨度，单位毫秒
    - EXPIREAT: 过期时间节点-时间戳，单位秒
    - PEXPIREAT: 过期时间节点-时间戳，单位毫秒
        


    










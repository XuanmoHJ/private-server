# SimpleKV

整体架构和核心模块 SimpleKV 数据模型与操作接口 键值数据库： 1。不包含聚合运算 2。基本数据模型 key-value

value支持的数据结构体现在：性能，空间利用差异 基本操作：put/set ，get ， delete ， scan ，exists

不同操作对redis访问速率的影响

内存：读写快，断电数据丢失 硬盘：效率受外部键盘读写影响

基本组件： 访问框架，索引模块，存储模块 访问模式：函数库调用（动态链接库）/ 网络框架

通讯：网络链接处理，网络协议解析，数据存储

索引模块（哈希表，B+树，字典树）选型体现：性能，空间差异，并发控制

内存分配器格外重要

持久化方式：文件

作业：实现一个SimpleKV，键值对 问题：SimpleKV 与redis的区别

# 认识redis

为什么快？ 内存读写 + 高效的数据结构

底层数据结构（六种）：简单动态字符串，列表，哈希表，跳表，压缩列表，整型数组

键值结构组织： 哈希表 ， 哈希桶（一个数组，保存的是entry），entry（key和value的指针） 哈希冲突：链式哈希，同一个哈希桶中的entry元素，通过next指针形成链表，也叫哈希冲突链。
为解决哈希链表过长而导致查询缓慢问题，引入rehash机制

rehash原理：

rehash时机：渐进性hash与定时任务

慢操作有那些？与数据结构有关系

压缩列表：类似数组，但在表头有三个字段表示长度（zlbytes），尾部偏移量（zltail），entry个数（zllen） 跳表：多级索引，金字塔结构

四字口诀：单元素操作是基础，范围查找非常耗时，统计高效，

redis 为什么快

底层数据结构（六种）：

哈希冲突 rehash 装载因子

集合数据如何操作

相关命令： 单元素操作是基础:
范围操作非常耗时；SCAN 统计操作通常高效； 例外情况只有几个

为什么说redis是单线程的： 单线程IO+多写单线程 数据结构+多路复用机制

网络IO处理:accept ，recv select + epoll

非阻塞模式：主动socket ， 被动/监听socket

IO多路复用机制：一个线程处理多个IO流，允许多个

持久化：AOF日志+RDB快照

写后日志（主线程）：先执行命令后存储文件，记录每一条命令。 1。避免错误命令的记录/不产生阻塞 2。风险：写命令/写磁盘 配置项： 同步写回：高可靠性，影响性能，数据会丢失 每秒写回：避免影响性能，数据会丢失，折中 操作系统控制写回：

AOF重写机制（子线程）：

内存快照：内存中的数据在某一时刻的状态 1。 对那些数据做快照（取景问题）：全量快照 save（阻塞） 和bgsave（非阻塞） 2。 快照执行期间是否可被修改：写操作时，主线程生成副本，bgsave会直接读取副本生成快照 3。
什么时候生成快照：频率-磁盘压力/fork操作阻塞主线程-> 增量快照（引用额外空间）

4.0版本以上提出混合使用概念：不同时刻修改记录AOF，生成快照后清空AOF

宕机-如何恢复

主从库同步，多写分离，主写从读 命令：replicaof 三个阶段：主从建立链接， 生成RDB文件，传输RDB文件 主-从-从及联模式分担全量同步压力，和fork开销

replication buffer and rep_backlog_buffer

rep_backlog_buffer 环形缓存区：从库读写慢时会导致数据不一致

三种模式：

主库发生故障，会影响同步与写操作，故需要故障转移即哨兵机制

哨兵机制基本流程：监控，选主，通知

监控： 主观下线 和 客观下线 误判 引入多实例哨兵集群，减少误判， 少数服从多数 (n/2 +1)

选主： 筛选条件：在线状态+网络状态 打分（三轮）：优先级（高） + 复制进度（快） + 从库ID（小）

哨兵集群

多实例间，通过pub/sub 发布订阅机制与主库产生联系，从而获取各个实例的ip和端口，从而相互之间就可建立链接。 通过主库info命令，获取从库信息，

quorum值

哨兵实例宕机后的Leader哨兵选举

只有两个实例时，需要拿到2票才能进行主从切换，如果其中一个宕机，则会导致无法进行故障转移。故哨兵集群至少需要三个实例。

保证所有的哨兵实例配置一直，down-after-milliseconds主管下线的判断值，否者会导致无法达成一致

# 切片（分片）集群

latest_fork_usec 指标： 最近一次fork耗时

纵向扩展：持久化时，增量数据导致阻塞，且受硬件和成本限制 横向扩展：

切片集群和redis cluster的区别

redis cluster ： 采用hash slot(哈希槽)，共有16384个 cluster create : 自动均分hash slot命令 cluster meet: 手动建立实例链接，生成集群 cluster addslots:
手动分配hash槽，需要注意的是，需要全部分配16384个，集群才可用

客户端如何找到数据在哪个实例上

重定向机制

主线程，子进程，后台线程

问题： 这些数据结构都是值的底层实现，键和值本身之间用什么结构组织？ 为什么集合类型有那么多的底层结构，它们都是怎么组织数据的，都很快吗？ 什么是简单动态字符串，和常用的字符串是一回事吗？

# 答疑

    - 两大维度，三大主线
        - 应用纬度：数据结构，缓存策略，集群应用
        - 系统纬度：底层数据结构，内存分配器 ，持久化，集群
    - 整数数组和压缩列表
        - 整数数组内存分配紧凑，避免开销
    - 基本IO模型潜在性能瓶颈
    - AOF 重写过程风险
        - 复制过程，阻塞主线程
        - 
    - 内存资源和CPU资源
        - swap机制
        - 主线程/子线程/后台线程 竞争CPU
    - 主从库不使用AOF，而使用RDB
    - 主从切换能否进行正常操作
    - 无感知中断
        - 哨兵
    - 哨兵-主/客观下线判断
    - 为什么不将实例和键值对关联存储成表？

* rehash 时机和执行机制

# 学习redis三本参考书+命令网站+源码阅读

# 如何学习redis

    -掌握数据结构和缓存的基本操作方法
        - 底层数据结构
        - 五种基础数据类型+三种拓展数据类型（HypeLoglog/Geo/BitMap）
        - 典型问题的解决方案：穿透/雪崩
        - 持久化/切片集群（高可靠，高性能，易扩展）
    -主从复制/哨兵/切片集群/持久化（AOF/RDB）
        - 高可靠性：持久化 -> 故障恢复（主从恢复）-> 自动主从切换（哨兵）
        - 高性能：单机 -> Cluster集群（水平扩展能力-扩容/容灾能力）
    redis性能问题：
        - 使用层面
        - 运维层面
    -分布式系统原理
        - 分布式CAP
        - 分布式事务

    1。保持好奇心-思考和挖掘能力
    2。不要自我设限
    3。源码实战（二八定律）
    4。文章输出（对知识的梳理）
    5。系统化学习，细化任务（番茄学习法）
    6。时间成本和精力投入

# redis 客户端

    - RESP2 协议
        - 交互内容：命令/键/值/键值ok回复/整数回复/错误信息
        - 五种编码格式类型
            - 简单字符串类型
            - 长字符串类型（二进制安全）
            - 整数类型
            - 错误类型
            - 数组类型

# QA

* Redis 缓存具体是怎么工作的？
* Redis 缓存如果满了，该怎么办？
* 为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？
* Redis 的内存毕竟有限，如果用快速的固态硬盘来保存数据，可以增加缓存的数据量，那么，Redis 缓存可以使用快速固态硬盘吗？

热key 提高访问速度 计算机三层存储架构：CPU，内存，磁盘 CPU末级缓存LLC用于缓存内存中的数据，内存中的高速页缓存（page cache），用来缓存磁盘中的数据。
1。缓存一定是一个快速子系统（redis），用于避免从慢速子系统（数据库）中获取数据 2。缓存系统容量大小要小于后端慢系统，我们不肯呢个把所有的数据保存在缓存中
3。缓存中的数据需要按照一定的规则淘汰数据，写回后端系统中，而新的数据需要从后端系统中读取并写入缓存 缓存命中 缓存缺失 -> 缓存更新 缓存数据一致性 缓存穿透 缓存击穿 缓存雪崩
只读缓存：读取数据时从redis访问，发生变更时操作数据库，并删除缓存。在缓存缺失时，重新从数据库读取并更新缓存（保障了数据的可靠性，不会丢失）
读写缓存：读写都在redis端，然后使用同步直写（保证数据可靠性，访问速度慢）/异步写回（降低访问延迟，数据有丢失风险）两种策略 缓存数据的淘汰机制： 八二原理：20%的数据贡献了80%的访问 长尾效应和重尾效应？

** 建议缓存容量设置为总数据量的15%-30% 兼顾访问性能和内存开销

## 缓存淘汰策略：

1。 是否回进行数据淘汰-noviction（否）和7种（是） 2。 按照过期时间淘汰（4种）和按照数据范围淘汰（三种）

** 不淘汰数据策略 - noevection策略：缓存空间满的时候(达到了maxmemory值)，不对数据进行淘汰，而是停止提供写入服务并返回错误信息
** 根据过期时间淘汰数据策略 - volatile-random : 对设置了过期时间的键值对，随机淘汰 - volatile-ttl： 对设置了过期时间的键值对，按过期时间的先后顺序进行淘汰 - volatile-lru：
对设置了过期时间的键值对，按最近最少使用的策略进行淘汰 - volatile-lfu： 对设置了过期时间的键值对，按使用频率最少的策略进行淘汰 - allkeys-random： 对所有的键值对，随机淘汰 - allkeys-lru：
对所有的键值对，按最近最少使用的策略进行淘汰 - allkeys-lfu： 对所有的键值对，按使用频率最少的策略进行淘汰

### LRU算法

概述： 维护一个双端链表，最近访问的键值对移动到最左边MRU端，最右端则是LRU端，淘汰数据的时候，从最右端开始往前淘汰

LRU算法因为需要额外的内存空间，以及移动淘汰数据时会对redis性能有所损耗，故redis对该算法进行了些简化。 1。
对每一个数据，其RedisObjec中的lru属性记录最近访问的时间戳。执行淘汰策略的时候，随机从内存中抓取N数据，然后把lru最小的淘汰掉。抓取的数据大小N由配置参数【maxmemory-samples】决定。 2。
当需要再次淘汰数据的时候，会再挑选出一批数据B放入上次的候选淘汰数据集合A中，其中挑选的数据B中的lru要小于候选集合A中的值。当候选集合A的个数到达【maxmemory-samples】的值时，就会触发淘汰，将A中最小的lru淘汰出去。

实战建议：

- 存在冷热数据区分的时候，建议使用allkeys-lru
- 冷热数据区分不明显的时候，建议使用allkeys-random
- 如果业务有置顶需求，建议使用volatile-lru策略，同时对于置顶数据不设置过期时间，这样置顶数据不会过期，而其他的数据可以按照lru策略进行淘汰

### LFU算法

    - 概述： 

### 对淘汰数据的处理
    - 干净的数据，可直接删除
    - 脏读数据，写回数据库。解决方案，缓存发生变更时写回到数据库，或者数据库发生变更时更新缓存数据，以解决脏读问题

### 缓存数据一致性问题
    - 缓存有数据，和数据库值是否一致
    - 缓存无数据，数据库中值是否时最新值 解决方案：
        - 保证缓存和数据库的修改删除的原子性，要么都成功，要么都失败。
        - 通过消息队列的方式，实现重试机制。只有全部更新成功新的数值才从消息队列中删除
        - 在删除/变更数据库和缓存的操作过程，发生了其他线程对于数据的读取，此时有两种情况：
            - 先删除缓存，后更新数据库数据。在数据更新数据库未完成前发生读取请求，出现数据不一致问题，可使用【延迟双删】的方式，减小数据不一致发生的概率。
            - 先更新数据库，后删除缓存。此种情况对于业务影响最小，只有更新db后，删除cache前，很小一部分发生脏读。如果一定要保证数据一致性，可在所有操作完成之前，将用户并发请求暂存，待全部完成后，在执行。

### 缓存雪崩，缓存击穿，缓存穿透问题

    - 缓存雪崩
        - 概述：当大量数据同时过期或者redis实例宕机时，就会导致大量的请求堆积到数据库，从而引发应用不可用。
        - 表现：数据库负载突增/redis实例宕机，导致请求延迟甚至是大量请求无响应
        - 解决方案：
            - 1. 杜绝大量的key同时失效，如果因业务需要则可以对失效时间添加一个一定时间内的随机数比如1-3分钟，这样即可让key在相近时间失效，也可防止其同时大批量失效而打到数据库
            - 2. 熔断降级和限流，当redis实例发生宕机或者发生雪崩时，对缓存接口进行熔断降级，返回预定义信息，比如非核心的属性信息。监控数据库可以支撑的数据压力，当达到阈值时，对接口进行限流。主要针对的时核心数据信息
            - 3. 从redis部署上预防，比如主从节点，当主节点发生宕机的时候，重新选举并提升从节点为主节点，以保证缓存服务高可用。例如sentinel模式
    
    - 缓存击穿
        - 概述： 当高并发发生在热点数据失效时，就会击穿缓存系统，而将压力打到数据库中
        - 表现： 数据库负载突增，热点数据失效
        - 解决方案：
            - 1. 对于热点数据延长其失效时间，甚至是不设置过期时间
    
    - 缓存穿透
        - 概述： 发生高并发时，缓存不被命中，同时也不在数据库中。（主要来源于恶意攻击）
        - 表现： 缓存缺失，数据库压力突增
        - 解决方案：
            - 1. 对不被命中或者为null的值设置缺省值
            - 2. 通过布隆过滤器判断数据是否存在，而减轻数据库压力
            - 3. 接口做安全性校验，防范恶意攻击
    
    - 布隆过滤器
        - 概述： 由一个初始值都为0的数组+N个哈希函数组成，可以快速判断是否数据是否存在
        - 原理： 
            - 1. 使用N个哈希函数，分别计算出该数据的哈希值，得到N个哈希值
            - 2. 把这N个哈希值对Bit数组的长度取模，得到每个哈希值在数组中对应的位置
            - 3. 把得到的位置，标记为1，即表示该数值存在。
        - 运用：判断数值是否存在，重复原理上的第一第二个步骤，如果得到的N个位置，在bit数组对应中存在一个不为1的情况，即表示数据不存在，没有被布隆过滤器标记过
        - 实际使用：
            - 1. 数据写入数据库时，使用布隆过滤器做标记
            - 2. 可使用redis来实现布隆过滤器，可提升访问性能

### 缓存污染

    - 概述： 放于缓存的数据，访问次数较少，甚至无访问，就会一直占用缓存空间，当缓存空间满的时候，需要执行淘汰策略，从而因为执行额外的操作，影响性能，这就是所谓的缓存污染。
    - 解决方案： 
        - 1. volatile-ttl: 在明确数据被访问情况下，可使用volatile-ttl来淘汰数据
        - 2. volatile-lru 和 allkeys-lru 策略：通过使用时间戳来定义最近最少使用淘汰策略，数据范围从过期时间到全部key
        - 3. volatile-lfu 和 allkeys-lfu 策略：在lru基础上，添加count访问计数来定义最近访问频率最小淘汰策略。即从访问时效性和访问次数层面做比较

### 缓存并发访问问题

    - 概述：多个实例访问redis缓存时，会导致数据不一致问题，主要由修改缓存导致
    - 解决方案：加锁/原子性操作
        - 加锁：需要考虑分布式锁，且加锁会阻塞其他操作，导致并发性能下降
        - 原子性操作： 
            - 1. 可以把多个操作，合并成一个操作指令执行，也就是单命令指令，比如INCR和DECR命令。适用于数据简单的增减
            - 2. 使用lua脚本，适用于多层逻辑判断，保障其一次性执行。注意需要避免把不需要并发控制的操作写入脚本中

### 分布式锁

    - 概述：解决分布式系统中加锁问题
    - 要求：
        - 1. 加解锁涉及到多个操作（读锁/检查锁/写锁），需要保证这些操作的原子性
        - 2. 需要设置过期时间，以避免死锁
        - 2. 共享存储系统保存了锁变量，需要保证其唯一性和可靠性，进而保证锁的可靠性
    - 实现：
        - 基于单个节点实现分布式锁：setnx|px|ex 命令 或者lua脚本
        - 基于多节点实现分布式锁： redlock算法（半数以上加锁成功才算成功，且某个节点宕机不影响可用性）

### 事务机制

    - 概述：一个事务中的操作要么全部完成，要么全部失败。即需要提供原子性，一致性，隔离性，持久性等保证，就是所谓的ACID
    - 实现： 通过MULTI 和 EXEC命令实现事务开启与提交，以保证多个操作共同执行。在执行EXEC之前，命令只是放在了队列中，且可以通过DISCARD来取消事务，但不存在事务回滚机制
    - 现象：
        - 1. 命令入队就报错，会导致事务执行失败，可以保证原子性/一致性，比如事务执行过程中，若出现命令非法情况时，所有命令都不会执行
        - 2. 命令入队成功，但执行报错，不保证原子性/一致性，如类型不一致或者非法的情况下，只会提示错误的命令，其他命令将被执行
        - 3. 在执行EXEC命令之前，实例宕机：
            - 开启了AOF ,但事务未写入AOF文件，重新回复后由于事务未写入执行，可保证原子性/一致性
            - 开启了AOF，但部分事务已写入AOF文件，重新回复后，可通过redis-check-aof来清除已经执行的事务，从而保证原子性与一致性
            - 未开启AOF，重启后事务执行数据就都没有了，谈不上原子性，但保证了一致性
            - 开启了RDB，因为事务执行过程中，是无法写入RDB的，所以回复之后也谈不上原子性了，但保证了一致性
        -关于隔离性：
            - 并发操作发生在执行EXEC命令之前，需要通过watch命令来保证隔离性，否则无法保证
            - 发生在EXEC命令之后，则可以保证。因为redis是单线程的。
        -关于持久性：
            - 事务的持久性取决于redis的持久化配置
            - 若未开启aof 和 rdb，则肯定无法保证持久性
            - 事务执行之后，在下一个RDB未写入时发生了实例宕机，则无法保证持久性
            - aof取决与no，everysec，allways三个配置项，但都可能出现数据丢失的情况无法保证持久性
            - 总结：故对于redis来说，其持久性属性都是得不到保证的
        -总结：redis可以保证一致性与隔离性，命令语法正确时可保证原子性，但无法保证持久性，且持久性也不是redis应该关注的点。
    - 实际运用：
        -1. 严格按照redis命令规范执行
        -2. 在使用事务的时候，可通过pipeline来一次性提交命令，即可保证事务隔离性，又提高了性能，避免反复操作而提高IO开销
        -3. 虽然使用了pipline保证了事务隔离性，但在需要保证原子性的情况下，watch命令还是需要的，以避免在执行事务前，数据发生了变更。

### 主从同步与故障切换

    - 概述：通过分库分担主库压力，可实现读写分离的同时，进行故障自动转移和回复，提供高可靠性
    - 现象：主从数据不一致，读到过期数据，配置不合理导致服务挂机
        - 主从数据不一致： 因主从复制异步执行缘故导致从库读取的数据和主库最新数据不一致
            - 1. 主从之间网络延迟，所以我们要尽量保证主从之间硬件层面网络的良好状况
            - 2. 从库虽然接收到了同步命令，但当前可能处于执行其他复杂度高的命令操作（如集合）而阻塞，若这段时间内主库数据再次法身变更，从库数据将不一致。此种情况下，可以利用通过info replicationm命令来提供一个外部监测程序监测主库的进度信息[master-repl-info]和从库的进度信息[slave-repl-info]，当两者进度信息差值超过设置阈值时，将断开从库的读取连接，等数据一致后再回复。但要注意为避免导致大部分甚至时全部从库不可用，这个阈值需要配置大一些。
            - 3. slave-server-stale-data配置项：设置了从库能否处理数据读写问题，可设置为no，这样从库只能服务INFO，SLAVEOF命令，可避免从从库中读到不一致的数据。另外需要注意与[slave-read-only]的区别，该配置项设置从库能否处理写命令，当为[yes]的时候，表示只能处理读请求
        - 过期数据脏读：由redis过期数据删除策略而引发的脏读现象。过期删除策略：惰性删除（再次调用时因过期而执行删除，否则将滞留）与定期删除（100ms执行一次随机数据抓取，若过期则删除）
            -1. 删除操作在主库执行，从库不会执行。若是惰性删除策略，在3.2版本以前，redis从库会返回过期数据，但3.2版本之后，从库虽不会删除，但返回空
            -2. 定时删除，为避免影响性能，每次执行的删除数据量不会太大，且是随机的。故已过期未被删除的数据会被滞留而产生脏读
            -3. 过期时间命令EXPIRE 和 PEXPIRE 命令，在主从命令同步时，因为同步需要时间，就会导致主从库实际过期时间出现偏差。比如主库设置过期时间60s，但同步全量花费了1分钟，那么在从库接收到命令并执行之后，就导致从库key的过期时间整体跨越了两分钟，而此时主库在一分钟之前数据就已经过期了。故在实际运用当中建议使用expireat 和 pexpireat 命令来设置过期时间节点。这样可避免增量的发生。但需注意主从服务器时间一致。
        - 配置项不合理：
            - 1. protected-mode配置项：限定了哨兵模式下是否可被其他实例访问。当设置为[yes]的时候，只能被本地服务器访问。故[yes]的情况下，将导致哨兵实例间无法通信，阻塞主从同步，当主库发生故障时，将导致主从无法切换，从而导致redis不可用。因此使用哨兵模式下，要配置为[no]，即保证了主从切换，也保证了哨兵的安全性。
            - 2. cluster-node-timeout配置项：设置了redis-cluster中实例响应心跳消息的超时时间。当主从发生切换时，由于时间过长，就会导致个别实例被判定异常，而集群选举必须要求半数以上的实例正常，此时就可能导致主从切换失败，而引发整个集群不可用。故实际业务中，可增大该配置项数值，比如[10-20s]

### 关于设置过期时间命令

    - EXPIRE : 过期时间跨度，单位秒
    - PEXPIRE: 过期时间跨度，单位毫秒
    - EXPIREAT: 过期时间节点-时间戳，单位秒
    - PEXPIREAT: 过期时间节点-时间戳，单位毫秒
        
### 主从集群脑裂问题
    - 概述：所谓脑裂就是当集群因某种原因而导致出现了两个主体，客户端写操作写入了不同的主体，从而引发了脑裂现象。
    - 现象：
        - 1. 主库发生假死故障，引发主从切换。
        - 2. 主从切换完成过程中，原主库恢复，使得某些客户端依旧连接原主库，执行写入操作
        - 3. 主从切换完成后，原主库需要同步新主库数据，此时操作是先清空本地数据，然后加载新主库同步过来的数据。此时由于清空了主从切换过程中产生的写操作，从而导致了数据缺失现象
    - 解决方案：
        - 1. 通过min-slaves-to-write 和 min-slaves-max-lag两个命令来限制主从切换过程中，原主库对于客户端写操作请求的接收。
        - 2. min-slaves-to-write 设置了主库能同步的最少从库数量
        - 3. min-slaves-max-lag 设置了主从数据同步时，从库向主库发送ACK最大延迟时间
    - 实例：
        - 1. 假设当前集群有主从五个节点，三个哨兵实例，当主库发生假故障被判定客观下线的时候，此时哨兵会重新选举一个从库提升为主库，并将原主库下降为从库。
        - 2. 若此时主从切换过程中，原主库回复可用，且发生了写操作请求，此时将导致客户端与原主库请求有效，从而将会有部分数据写入原主库
        - 3. 当主从完成切换之后，新主库会向从库发送新的数据同步请求，而其他从库的操作时清空本地数据-加载同步数据。故此时原主库降级为从库的时候，由于清空本地数据，而导致了脑裂现象，其主从切换过程中产生与本地的数据将因清空而丢失。
        - 4. 针对此现象，假如我们将min-slaves-to-write设置为1 ， min-slaves-max-lag 设置为12s ， down-after-milliseconds 设置为10s（哨兵心跳监测有效时长），其主库假死时间为15s。在此过程中由于原主库发生了假死故障，在10s内无法响应哨兵实例的心跳监测，而被判定了主观下线，又由于在被卡住15s的时间内，无法实现12s内主从同步确认，从而使得原主库无法再接收从库请求。如此一来，就不回发生主从同步过程中因原主库假死恢复，而引发脑裂问题，从而导致数据丢失。
    - 总结：
        假设从库有 K 个，可以将 min-slaves-to-write 设置为 K/2+1（如果 K 等于 1，就设为 1），将 min-slaves-max-lag 设置为十几秒（例如 10～20s），在这个配置下，如果有一半以上的从库和主库进行的 ACK 消息延迟超过十几秒，我们就禁止主库接收客户端写请求。这样一来，我们可以避免脑裂带来数据丢失的情况，而且，也不会因为只有少数几个从库因为网络阻塞连不上主库，就禁止主库接收请求，增加了系统的鲁棒性

### codis 原理与cluster区别
    - 架构组成：
        - codis server：重写后的redis实例，增加了额外的数据结构，支持数据迁移，增加了集群操作相关的命令，主要支持具体的读写请求。
        - codis proxy：接收并转发客户端请求到具体的codis server。
        - codis dashboard 和 codis fe：集群管理，前者执行集群操作，后者提供可视化界面
        - zookeeper集群：由多实例组成用于保存集群元数据，如server位置，proxy的连接信息等等
    - 集群治理：
        - 数据分布：
            - 1. server与slot分配：共有1024个slot槽，可手动分配，也可通过dashboard自动分配
            - 2. 数据与slot分配： 通过CRC32算法与1024取模，计算出数据对应的slot槽
            - 3. 数据路由表：server与slot的映射关系会形成一张路由表，由dashboard管理，同步到各个server并缓存到本地，同时整张表的数据会保存在zookeeper集群中，以防止集群故障出现映射关系丢失。
            - 4. 与cluster的区别在于数据路由表，cluster中路由表发生变更的时候，是通过各个server之间相互通讯来完成新的同步，对集群的网路资源要求较高，而codis则有dashboard同步更新。  
        - 集群扩容：增加server/proxy
            - 增加server
                1. 根据slot的粒度需要对数据进行迁移，涉及到序列化->网络传输->反序列化->ack确认->源数据删除
                2. 从要迁移的slot中随机选取部分数据，迁移到新的server中，循环往复直到迁移完成为止
                    - 同步迁移：数据迁移过程中，该slot不可用，目的server收到数据后，给原server返回ACK确认信息，原server收到该信息后，会将已迁移的数据在本地删除
                    - 异步迁移：为解决阻塞问题，数据迁移过程中，迁移数据为可读不可写，以避免出现数据不一致的问题。对于bigkey采用化整为零的方式，分批处理。但会破坏原子性，如发生故障，会导致bigkey的数据出现在两个server中。为解决该问题，引入了临时过期时间机制。若发生故障，已迁移的bigkey会过期掉，反之迁移完成后，会对临时过期时间进行删除
                3. 可通过slotsmgrttagslot-async的参数numbers，配置单次迁移key的数量。
            - 增加proxy：当proxy连接无法支持大量业务操作的时候，可通过增加proxy来进行扩容 
                - 启动新的proxy，并通过dashboard 添加到集群中。
                - zookeeper中保存有所有proxy的访问信息，客户端可通过zookeeper进行拉取
        - 对单实例的兼容方案：
            - codis使用的是通过proxy转发来实现客户端与实例的交互，而不是cluster的直接连接。所以客户端不需要考虑兼容性问题，完全有proxy和dashboard处理
        -可靠性：对于分布式系统而言，系统个数越多，潜在风险点也就越多
            - 通过部署server group（主从）和哨兵集群来实现主从切换和提升高可用性
            - 通过zookeeper的多实例选举模式，来保证proxy的可靠性，只要半数以上节点存在就能继续服务。proxy无状态，若出现故障，只需重启proxy，然后从zookeeper中重新获取路由表即可使用
    -优劣：
        - 成熟稳定，兼容单实例客户端，支持异步迁移
        - 基于3.2.8版本开发，不支持后续出现的新命令以及新特性
    -建议：当存在多条业务线的时候，可启动多个dashboard，并指派一个dashboar管理一条业务线，可实现隔离管理

### redis支撑秒杀关键技术与实现
    - 概述：秒杀系统在于限时限量
    - 负载特征：
        - 瞬时高并发访问：传统数据库每秒访问量一般为千级别，而redis至少是万级别。故此种情况下，先通过redis拦截大量请求，以免压垮数据库
        - 读操作远远大于写操作，且读操作多是简单查询。
    - 秒杀环节处理机制
        - 秒杀活动开始前：多为商品详情查询，可通过页面静态化方式，使用CDN或浏览器缓存来降低服务端的访问压力
        - 秒杀活动开始后：库存查验，下单，库存扣减。再次过程中，库存查验将承担最大压力，故可通过redis来减压。同时下单操作可交由数据库处理，因为涉及多张表事务，且到了下单环节，流量压力已不大。而库存扣减则不能交由数据库处理，因为库存的更新会影响库存查验，容易出现超卖现象。要保证库存查验和库存扣减的原子性。另外还需注意恶意攻击拦截，请求分段放行，消息队列处理订单等操作
        - 秒杀活动结束后：商品详情可能还持续一段时间的访问量
    -redis支撑：
        - 多个秒杀商品时，可使用切片集群模式，通过对商品Id的CRC算法来将不同的商品绑定到不同的实例当中，以避免单实例高并发访问问题，但若为单个商品秒杀，使用切片集群，容易被导致，请求倾斜/商品卖不完等现象。 
        - 保证库存扣减原子性：原子命令/分布式锁/lua脚本
        

### 切片集群模式

#### 数据倾斜
    - 概念：所谓数据倾斜就是请求被集中到某个实例中，主要分为两类。一类时数据量上分配不均，一类则是某个实例上的数据成为了热点key，被大量集中访问。
    - 数据量倾斜
        成因：bigkey/slot分配不均/Hash Tag
        解决方案：
            - 尽量避免bigkey，把集合类型的bigkey拆分成多个小集合分散保存
            - 对于slot分配不均问题，可对分配不均的slot进行数据迁移。具体为通过cluster slots命令查看分配情况，使用cluster setslot设置要迁入的目标实例，迁出的源实例，以及slot所属实例。使用cluster getkeysinslot获取其key数量，使用migrate命令把一个key从源sh实例实际迁移到目标实例。例子：将slot 300 从实例3迁移至实例5
                -1. 在实例5中使用命令cluster setlot 300 importing 3 表示要从实例3上迁入slot300
                -2. 在实例3中使用命令cluster setlot 300 migrate 5 表示要从实例3上将slot300迁出至实例5
                -3. 在实例3中使用命令cluster getkeysinslot 300 100 表示从slot300中获取100个key
                -4. 在实例3中使用命令migrate host port key 0 timout 表示将为key的数据迁移至目标实例的0号数据库中，迁移超时时间为timeout
                -5. 在3.0.6版本后也可使用migrate host port "" 0 timout keys key1 key2 key3 表示将多个keys做批量迁移
            - Hash Tag：指加在键值对key中的一对花括号，例如"user:login:{userId}".
                -概述： 存在花括号的时候，客户端对key进行CRC16计算的时候，只针对花括号内的key，否则针对的是整个key，如上面针对的是"userId"，反之针对的是"user:login:userId"
                -意义：用于cluster或者codis中实现事务和范围查询。因为在花括号的关系，不同的key，相同的Hash tag会被放入同一个实例中，从而实现在同一个实例完成事务和范围查询。如"user:login:{userId}"和"user:pv:{userId}"就可以对这两个做范围查询
                -缺陷：会导致数据倾斜，大量的数据集中在同一个实例中。
                -解决建议：如果容易导致数据倾斜，则不建议使用Hash tag来进行数据切片。因为事务和范围查询虽然不能跨实例，但可以在客户端中做执行。而数据倾斜会大导致实例不稳定，造成服务不可用。
    - 数据访问倾斜
        成因：热点key出现在某个实例中
        解决方案：多副本？即复制多分数据，给key添加随机前缀，让其分布到不同的实例中。取数据的时候也加上随机前缀，即可从不同的实例中获取到相同的数据。但热点key必须是只读不可写，否则将导致数据不一致
    -总结：在构建切片集群的时候，尽量使用大小配置相同的实例，以避免因资源问题，而导致slot分配不均，从而引发数据倾斜。

#### 制约cluster规模的关键因素
    - 概述：通信开销是制约其规模的关键因素。在官方文档中cluster的实例上限是1000，但实际上可能达到800个就会导致吞吐量不升反降。因为实例间的通信开销会随着实例节点的增加而增加。
    - 实例间的通信：
        -1. 实例间通过gossip协议进行通信
        -2. gossip协议原理：每一个实例会按照一定的频率，从集群中随机选中一些实例，发送PING消息用来监测实例是否在线并交换彼此的信息。ping消息中包含了当前实例的状态信息，其他实例的状态信息（集群实例的十分之一），slot映射表等。收到ping消息的实例，正常情况下会返回PONG消息。pong的消息的内容与ping消息一样。gossip协议可以保证在一定时间后每一个实例都可以获得其他所有实例的状态信息，同时也保证了新节点加入，节点故障，slot变更等发生时，也可以通过ping 和 pong消息来完成集群状态在所有实例上同步。
        -3. 从原理上我们可知gossip协议收到了通信消息大小和频率的影响。gossip消息结构体包含了104个字节，另外为了让slot映射表在不同实例间传播，ping消息还带了一个16384长度的bitmap，bitmap的每一位代表一个slot，1则表示slot属于当前实例
        -4. 实例间通信频率：
            - 每个实例每秒会向其他实例发起一次PING。（实例起来后每秒会从本地实例列表中随机选取5个实例，然后找出一个最久没有通信的实例发送PING消息）
            - PING消息选取和发送的方式，会使得某些长久都没有通信的实例出现遗漏，从而导致某些实例的状态信息已过期。
            - 为解决上述可能出现的问题，实例会每隔100ms做一次心跳检测，对于那些PONG消息超时的实例，会重新发送PING消息。
    -总结：通过实例间通信的原理（消息大小与通信频率），我们可知实例间的通信对与集群的网络资源有着很大的占用。而要解决这个问题，我们可以从cluster-node-timeout 心跳检测超时属性入手，默认情况下是15s。我们可以适当延长这个属性值，比如改成20或者25，这样就可以减少实例间发送PING的次数，降低占用的网络带宽。但是这个属性值也不宜过长,否则发生实例发生故障的时候，将会等待这个数值时间后才能检测出故障，从而延长了故障恢复时间，进一步导致集群不可用。另外如果不是特别需要大容量集群，建议实例控制在400-500个。





